Who is Ilya Sutskever?
[
  "such person, and he agreed to be OpenAI’s CTO. Another keycofounder would be Andrej Karpathy, who had been at GoogleBrain, the search giant’s cutting-edge AI research operation. Butperhaps Altman’s most sought-after target was a Russian-bornengineer named Ilya Sutskever.Sutskever’s pedigree was unassailable. His family hademigrated from Russia to Israel, then to Canada. At theUniversity of Toronto he had been a standout student underGeoffrey Hinton, known as the godfather of modern AI for hiswork on deep learning and neural networks. Hinton, who is stillclose to Sutskever, marvels at his protégé’s wizardry. Early inSutskever’s tenure at the lab, Hinton had given him acomplicated project. Sutskever got tired of writing code to do therequisite calculations, and he told Hinton it would be easier if hewrote a custom programming language for the task. Hinton got abit annoyed and tried to warn his student away from what heassumed would be a monthlong distraction. Then Sutskevercame clean: “I did it this morning.”Sutskever became an AI superstar, coauthoring a breakthroughpaper that showed how AI could learn to recognize imagessimply by being exposed to huge volumes of data. He ended up,happily, as a key scientist on the Google Brain team.In mid-2015 Altman cold-emailed Sutskever to invite him todinner with Musk, Brockman, and others at the swankRosewood Hotel on Palo Alto’s Sand Hill Road. Only later didSutskever ﬁgure out that he was the guest of honor. “It was kindof a general",
  "at the swankRosewood Hotel on Palo Alto’s Sand Hill Road. Only later didSutskever ﬁgure out that he was the guest of honor. “It was kindof a general conversation about AI and AGI in the future,” hesays. More speciﬁcally, they discussed “whether Google andDeepMind were so far ahead that it would be impossible tocatch up to them, or whether it was still possible to, as Elon putit, create a lab which would be a counterbalance.” While no one",
  "embodied in thecompany’s name has shifted from the radical transparencysuggested at launch. When I bring this up to Sutskever, heshrugs. “Evidently, times have changed,” he says. But, hecautions, that doesn’t mean that the prize is not the same.“You’ve got a technological transformation of such gargantuan,cataclysmic magnitude that, even if we all do our part, successis not guaranteed. But if it all works out we can have quite theincredible life.”"
]


What did Elon Musk say about OpenAI?

[
  "really long way after that, maybe we’ll have systems that can docomplex stuff like proving mathematical theorems. Finally wewill have AI that can create new things and make art and writeand do these deeply human things. That was a terribleprediction—it’s going exactly the other direction.”The world didn’t know it yet, but Altman and Musk’s research labhad begun a climb that plausibly creeps toward the summit ofAGI. The crazy idea behind OpenAI suddenly was not so crazy.By early 2018, OpenAI was starting to focus productively onlarge language models, or LLMs. But Elon Musk wasn’t happy.He felt that the progress was insufﬁcient—or maybe he felt thatnow that OpenAI was on to something, it needed leadership toseize its advantage. Or maybe, as he’d later explain, he felt thatsafety should be more of a priority. Whatever his problem was,he had a solution: Turn everything over to him. He proposedtaking a majority stake in the company, adding it to the portfolioof his multiple full-time jobs (Tesla, SpaceX) and supervisoryobligations (Neuralink and the Boring Company).Musk believed he had a right to own OpenAI. “It wouldn’t existwithout me,” he later told CNBC. “I came up with the name!”(True.) But Altman and the rest of OpenAI’s brain trust had nointerest in becoming part of the Muskiverse. When they madethis clear, Musk cut ties, providing the public with the incompleteexplanation that he was leaving the board to avoid a conﬂict withTesla’s AI effort. His farewell came at an",
  "CNBC, he elaborated with an analogy: “Let’s say you foundedan organization to save the Amazon rainforest, and instead youbecame a lumber company, chopped down the forest, and soldit.”Musk’s jibes might be dismissed as bitterness from a rejectedsuitor, but he wasn’t alone. “The whole vision of it morphing theway it did feels kind of gross,” says John Carmack. (He doesspecify that he’s still excited about the company’s work.)Another prominent industry insider, who prefers to speak withoutattribution, says, “OpenAI has turned from a small, somewhatopen research outﬁt into a secretive product-development housewith an unwarranted superiority complex.”Even some employees had been turned off by OpenAI’s ventureinto the for-proﬁt world. In 2019, several key executives,including head of research Dario Amodei, left to start a rival AIcompany called Anthropic. They recently told The New YorkTimes that OpenAI had gotten too commercial and had fallenvictim to mission drift.Another OpenAI defector was Rewon Child, a main technicalcontributor to the GPT-2 and GPT-3 projects. He left in late 2021and is now at Inﬂection AI, a company led by former DeepMindcofounder Mustafa Suleyman.Altman professes not to be bothered by defections, dismissingthem as simply the way Silicon Valley works. “Some people willwant to do great work somewhere else, and that pushes societyforward,” he says. “That absolutely ﬁts our mission.”Until November of last year, awareness of OpenAI was largelyconﬁned to people",
  "both Musk and Altman believed that the safer course for AIwould be in the hands of a research operation not polluted bythe proﬁt motive, a persistent temptation to ignore the needs ofhumans in the search for boffo quarterly results.Altman cautioned me not to expect results soon. “This is goingto look like a research lab for a long time,” he said.There was another reason to tamp down expectations. Googleand the others had been developing and applying AI for years.While OpenAI had a billion dollars committed (largely via Musk),an ace team of researchers and engineers, and a lofty mission,it had no clue about how to pursue its goals. Altman remembersa moment when the small team gathered in Brockman’sapartment—they didn’t have an ofﬁce yet. “I was like, whatshould we do?”I had breakfast in San Francisco with Brockman a little morethan a year after OpenAI’s founding. For the CTO of a companywith the word open in its name, he was pretty parsimonious withdetails. He did afﬁrm that the nonproﬁt could afford to draw onits initial billion-dollar donation for a while. The salaries of the 25people on its staff—who were being paid at far less than marketvalue—ate up the bulk of OpenAI’s expenses. “The goal for us,the thing that we’re really pushing on,” he said, “is to have thesystems that can do things that humans were just not capable ofdoing before.” But for the time being, what that looked like was abunch of researchers publishing papers. After the interview, Iwalked him to the"
]

Is there any existencial threat with the development of AI?

[
  "a large neural network and data,”says Sutskever.To Altman, it was a mind-bending experience. “If you asked the10-year-old version of me, who used to spend a lot of timedaydreaming about AI, what was going to happen, my prettyconﬁdent prediction would have been that ﬁrst we’re gonna haverobots, and they’re going to perform all physical labor. Thenwe’re going to have systems that can do basic cognitive labor. A",
  "sidelines in discussions of how AI might affect the future of thespecies.\nPhotograph: Jessica Chou\nOpenAI’s San Francisco headquarters is unmarked; but inside,the coffee is awesome.Photograph: Jessica Chou",
  "thwart smaller startups and give an advantage to OpenAI andother big players. Altman denies this. While he has endorsed, inprinciple, the idea of an international agency overseeing AI, hedoes feel that some proposed rules, like banning all copyrightedmaterial from data sets, present unfair obstacles. He pointedlydidn’t sign a widely distributed letter urging a six-monthmoratorium on developing more powerful AI systems. But heand other OpenAI leaders did add their names to a one-sentence statement: “Mitigating the risk of extinction from AIshould be a global priority alongside other societal-scale riskssuch as pandemics and nuclear war.” Altman explains: “I said,‘Yeah, I agree with that. One-minute discussion.”As one prominent Silicon Valley founder notes, “It’s rare that anindustry raises their hand and says, ‘We are going to be the endof humanity’—and then continues to work on the product withglee and alacrity.”OpenAI rejects this criticism. Altman and his team say thatworking and releasing cutting-edge products is the way toaddress societal risks. Only by analyzing the responses tomillions of prompts by users of ChatGPT and GPT-4 could theyget the knowledge to ethically align their future products.Still, as the company takes on more tasks and devotes moreenergy to commercial activities, some question how closelyOpenAI can concentrate on the mission—especially the“mitigating risk of extinction” side. “If you think about it, they’reactually building ﬁve businesses,” says an"
]

What is so interesting about the story of OpenAI?

[
  "“I can’t emphasize this enough—we didn’t have a master plan,”says Altman. “It was like we were turning each corner andshining a ﬂashlight. We were willing to go through the maze toget to the end.” Though the maze got twisty, the goal has notchanged. “We still have our core mission—believing that safeAGI was this critically important thing that the world was nottaking seriously enough.”Meanwhile, OpenAI is apparently taking its time to develop thenext version of its large language model. It’s hard to believe, butthe company insists it has yet to begin working on GPT-5, aproduct that people are, depending on point of view, eithersalivating about or dreading. Apparently, OpenAI is grapplingwith what an exponentially powerful improvement on its currenttechnology actually looks like. “The biggest thing we’re missingis coming up with new ideas,” says Brockman. “It’s nice to havesomething that could be a virtual assistant. But that’s not thedream. The dream is to help us solve problems we can’t.”Considering OpenAI’s history, that next big set of innovationsmight have to wait until there’s another breakthrough as majoras transformers. Altman hopes that will come fromOpenAI—“We want to be the best research lab in the world,” hesays—but even if not, his company will make use of others’advances, as it did with Google’s work. “A lot of people aroundthe world are going to do important work,” he says.It would also help if generative AI didn’t create so many newproblems of its own. For",
  "training their own model and make elegant things that you canpublish papers on. You have to do this more tedious, lesselegant work.” That, he added, was something OpenAI was ableto do, and something no one else did.",
  "really long way after that, maybe we’ll have systems that can docomplex stuff like proving mathematical theorems. Finally wewill have AI that can create new things and make art and writeand do these deeply human things. That was a terribleprediction—it’s going exactly the other direction.”The world didn’t know it yet, but Altman and Musk’s research labhad begun a climb that plausibly creeps toward the summit ofAGI. The crazy idea behind OpenAI suddenly was not so crazy.By early 2018, OpenAI was starting to focus productively onlarge language models, or LLMs. But Elon Musk wasn’t happy.He felt that the progress was insufﬁcient—or maybe he felt thatnow that OpenAI was on to something, it needed leadership toseize its advantage. Or maybe, as he’d later explain, he felt thatsafety should be more of a priority. Whatever his problem was,he had a solution: Turn everything over to him. He proposedtaking a majority stake in the company, adding it to the portfolioof his multiple full-time jobs (Tesla, SpaceX) and supervisoryobligations (Neuralink and the Boring Company).Musk believed he had a right to own OpenAI. “It wouldn’t existwithout me,” he later told CNBC. “I came up with the name!”(True.) But Altman and the rest of OpenAI’s brain trust had nointerest in becoming part of the Muskiverse. When they madethis clear, Musk cut ties, providing the public with the incompleteexplanation that he was leaving the board to avoid a conﬂict withTesla’s AI effort. His farewell came at an"
]

Why did ChatGPT become some famous?

[
  "way: “You want to build larger andmore powerful intelligences and keep them in your basement?”Even so, OpenAI was stunned at the reaction to ChatGPT. “Ourinternal excitement was more focused on GPT-4,” says Murati,the CTO. “And so we didn’t think ChatGPT was really going tochange everything.” To the contrary, it galvanized the public tothe reality that AI had to be dealt with, now. ChatGPT becamethe fastest-growing consumer software in history, amassing a",
  "reported 100 million users. (Not-so-OpenAI won’t conﬁrm this,saying only that it has “millions of users.”) “I underappreciatedhow much making an easy-to-use conversational interface to anLLM would make it much more intuitive for everyone to use,”says Radford.ChatGPT was of course delightful and astonishingly useful, butalso scary—prone to “hallucinations” of plausible but shamefullyfabulist details when responding to prompts. Even as journalistswrung their hands about the implications, however, theyeffectively endorsed ChatGPT by extolling its powers.The clamor got even louder in February when Microsoft, takingadvantage of its multibillion-dollar partnership, released aChatGPT-powered version of its search engine Bing. CEONadella was euphoric that he had beaten Google to the punch inintroducing generative AI to Microsoft’s products. He taunted thesearch king, which had been cautious in releasing its own LLMinto products, to do the same. “I want people to know we madethem dance,” he said.In so doing, Nadella triggered an arms race that temptedcompanies big and small to release AI products before theywere fully vetted. He also a triggered a new round of mediacoverage that kept wider and wider circles of people up at night:interactions with Bing that unveiled the chatbot’s shadow side,replete with unnerving professions of love, an envy of humanfreedom, and a weak resolve to withhold misinformation. As wellas an unseemly habit of creating hallucinatory misinformation ofits",
  "Altman explains why OpenAI released ChatGPT when GPT-4was close to completion, undergoing safety work. “WithChatGPT, we could introduce chatting but with a much lesspowerful backend, and give people a more gradual adaptation,”he says. “GPT-4 was a lot to get used to at once.” By the timethe ChatGPT excitement cooled down, the thinking went, peoplemight be ready for GPT-4, which can pass the bar exam, plan acourse syllabus, and write a book within seconds. (Publishinghouses that produced genre ﬁction were indeed ﬂooded with AI-generated bodice rippers and space operas.)A cynic might say that a steady cadence of new products is tiedto the company’s commitment to investors, and equity-holdingemployees, to make some money. OpenAI now chargescustomers who use its products frequently. But OpenAI insiststhat its true strategy is to provide a soft landing for thesingularity. “It doesn’t make sense to just build AGI in secret anddrop it on the world,” Altman says. “Look back at the industrialrevolution—everyone agrees it was great for the world,” saysSandhini Agarwal, an OpenAI policy researcher. “But the ﬁrst 50years were really painful. There was a lot of job loss, a lot ofpoverty, and then the world adapted. We’re trying to think howwe can make the period before adaptation of AGI as painless aspossible.”Sutskever puts it another way: “You want to build larger andmore powerful intelligences and keep them in your basement?”Even so, OpenAI was stunned at the reaction to ChatGPT."
]